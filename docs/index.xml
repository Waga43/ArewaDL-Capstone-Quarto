<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving
and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">

<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">

<front>


<article-meta>


<title-group>
<article-title>Deep Learning Based Classification of Nigerian
Traditional Attire</article-title>
</title-group>

<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Ibrahim</surname>
<given-names>Naziru Abdussalam</given-names>
</name>
<string-name>Naziru Abdussalam Ibrahim</string-name>

<xref ref-type="corresp" rid="cor-1">&#x002A;</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Saad</surname>
<given-names>Ahmad</given-names>
</name>
<string-name>Ahmad Saad</string-name>

<email>ahmedwafiqs@gmail.com</email>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Popoola</surname>
<given-names>Abdulwasiu Bamidele</given-names>
</name>
<string-name>Abdulwasiu Bamidele Popoola</string-name>

<email>waga43tech@gmail.com</email>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Abass</surname>
<given-names>Taiwo Soffiyah</given-names>
</name>
<string-name>Taiwo Soffiyah Abass</string-name>

<email>soffiyahabass1@gmail.com</email>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Akande</surname>
<given-names>Ayodeji</given-names>
</name>
<string-name>Ayodeji Akande</string-name>

<email>ayodejiakande2107@gmail.com</email>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Abdullahi</surname>
<given-names>Shamsu</given-names>
</name>
<string-name>Shamsu Abdullahi</string-name>

<email>engrdanalupalladan@gmail.com</email>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Sulaiman</surname>
<given-names>Abubakar Sadiq</given-names>
</name>
<string-name>Abubakar Sadiq Sulaiman</string-name>

</contrib>
<contrib contrib-type="author">
<name>
<surname>Abdurrazaq</surname>
<given-names>Yahya</given-names>
</name>
<string-name>Yahya Abdurrazaq</string-name>

<email>yahyarimi01@gmail.com</email>
</contrib>
<contrib contrib-type="author">
<name>
<surname></surname>
<given-names></given-names>
</name>
<string-name></string-name>

</contrib>
</contrib-group>
<author-notes>
<corresp id="cor-1"></corresp>
</author-notes>









<history></history>


<abstract>
This study presents a deep learning approach to classify images of
Nigerian traditional attire into their respective ethnic categories.
Utilizing Convolutional Neuraetworks (CNNs), specifically ResNet34 and
EfficientNet-B0 architectures, the project aims to automate the
identification of cultural garments, thereby contributing to the
preservation and appreciation of Nigeria’s rich cultural heritage.
</abstract>




</article-meta>

</front>

<body>
<sec id="introduction">
  <title>Introduction</title>
  <p>The culture of Nigeria is shaped by Nigeria’s multiple ethnic
  groups. The country has over 50 languages and over 250 dialects and
  ethnic groups “Culture – MFA Press Center”
  (<xref alt="n.d." rid="ref-noauthor_culture_nodate" ref-type="bibr">n.d.</xref>)
  . The three major ethnic groups are the Hausa-Fulani who are
  predominant in the north, the Yoruba who are predominant in the
  southwest, and the Igbo who are predominant in the south-east. In an
  effort to promote the rich cultural heritage of the country, the
  Ministry of Information, Culture and Tourism was created in the year
  2015.</p>
  <p>Nigeria’s over 250 diverse ethnic groups are distinguished by
  unique traditional attires that embody their cultural identities
  (<xref alt="“Culture – MFA Press Center” n.d." rid="ref-noauthor_culture_nodate" ref-type="bibr">“Culture
  – MFA Press Center” n.d.</xref>). Manual classification of these
  garments can be time-consuming and subjective. This project explores
  the application of deep learning techniques to accurately classify
  images of traditional Nigerian clothing, facilitating cultural
  education and digital archiving.</p>
</sec>
<sec id="methodology">
  <title>Methodology</title>
  <sec id="data-collection">
    <title>Data Collection</title>
    <p>Images representing various Nigerian ethnic attires were
    collected using custom Python scripts
    (<monospace>download_attire.py</monospace> and
    <monospace>download_attire_extended.py</monospace>). The dataset
    includes categories such as Yoruba, Hausa, Igbo, and others, with
    images depicting traditional garments in various settings.</p>
  </sec>
  <sec id="data-preprocessing">
    <title>Data Preprocessing</title>
    <p>The collected images underwent preprocessing steps, including
    resizing, normalization, and data augmentation, to enhance model
    generalization. The dataset was then split into training,
    validation, and test sets.</p>
  </sec>
  <sec id="model-architectures">
    <title>Model Architectures</title>
    <p>Two CNN architectures were employed Tan and Le
    (<xref alt="2019" rid="ref-tan_efficientnetU003A_2019" ref-type="bibr">2019</xref>):</p>
    <list list-type="bullet">
      <list-item>
        <p><bold>ResNet34</bold>: A 34-layer residual network known for
        its ability to mitigate vanishing gradient issues.</p>
      </list-item>
      <list-item>
        <p><bold>EfficientNet-B0</bold>: A model that scales depth,
        width, and resolution uniformly using a compound coefficient,
        achieving high accuracy with fewer parameters.</p>
      </list-item>
    </list>
    <p>Both models were fine-tuned on the dataset, leveraging transfer
    learning from pre-trained weights.</p>
  </sec>
  <sec id="training-and-evaluation">
    <title>Training and Evaluation</title>
    <p>Training was conducted using standard practices, including the
    use of cross-entropy loss and optimization via stochastic gradient
    descent. Model performance was evaluated based on accuracy,
    precision, recall, and F1-score on the validation and test sets.</p>
  </sec>
</sec>
<sec id="results">
  <title>Results</title>
  <p>Both models demonstrated strong performance in classifying
  traditional Nigerian attires:</p>
  <list list-type="bullet">
    <list-item>
      <p><bold>ResNet34</bold>: Achieved an accuracy of approximately
      85% on the test set.</p>
    </list-item>
    <list-item>
      <p><bold>EfficientNet-B0</bold>: Outperformed ResNet34 with an
      accuracy of around 90%, indicating better generalization
      capabilities.</p>
    </list-item>
  </list>
  <p>Confusion matrices and classification reports further highlighted
  the models’ proficiency in distinguishing between different ethnic
  attires.</p>
  <fig id="fig-loss">
    <caption><p>Figure 1: Loss over Epochs and Validation Accuracy over
    Epochs</p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="assets\loss-of-epochs-and-validation-accuracy.png" />
  </fig>
  <fig id="fig-confusion-matrix">
    <caption><p>Figure 2: Confusion matrix</p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="assets\confusion-matrix.png" />
  </fig>
</sec>
<sec id="discussion">
  <title>Discussion</title>
  <p>The superior performance of EfficientNet-B0 suggests its
  suitability for image classification tasks involving cultural
  garments. The results affirm the potential of deep learning models in
  automating the recognition of traditional attires, which can be
  instrumental in cultural preservation efforts.</p>
</sec>
<sec id="conclusion">
  <title>Conclusion</title>
  <p>This project successfully demonstrates the application of deep
  learning techniques in classifying Nigerian traditional attire. The
  developed models can serve as foundational tools for cultural
  education platforms, virtual museums, and fashion industry
  applications. Future work may involve expanding the dataset to include
  more ethnic groups and exploring real-time classification systems.</p>
</sec>
<sec id="acknowledgment">
  <title>Acknowledgment</title>
</sec>
</body>

<back>
<ref-list>
  <title>References</title>
  <ref id="ref-he_deep_2016">
    <element-citation publication-type="paper-conference">
      <person-group person-group-type="author">
        <name><surname>He</surname><given-names>Kaiming</given-names></name>
        <name><surname>Zhang</surname><given-names>Xiangyu</given-names></name>
        <name><surname>Ren</surname><given-names>Shaoqing</given-names></name>
        <name><surname>Sun</surname><given-names>Jian</given-names></name>
      </person-group>
      <article-title>Deep Residual Learning for Image Recognition</article-title>
      <source>2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</source>
      <publisher-name>IEEE</publisher-name>
      <publisher-loc>Las Vegas, NV, USA</publisher-loc>
      <year iso-8601-date="2016-06">2016</year><month>06</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-05-31">2025</year><month>05</month><day>31</day></date-in-citation>
      <isbn>9781467388511</isbn>
      <uri>http://ieeexplore.ieee.org/document/7780459/</uri>
      <pub-id pub-id-type="doi">10.1109/CVPR.2016.90</pub-id>
      <fpage>770</fpage>
      <lpage>778</lpage>
    </element-citation>
  </ref>
  <ref id="ref-tan_efficientnetU003A_2019">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Tan</surname><given-names>Mingxing</given-names></name>
        <name><surname>Le</surname><given-names>Quoc V.</given-names></name>
      </person-group>
      <article-title>EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks</article-title>
      <year iso-8601-date="2019">2019</year>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-05-31">2025</year><month>05</month><day>31</day></date-in-citation>
      <uri>https://arxiv.org/abs/1905.11946</uri>
      <pub-id pub-id-type="doi">10.48550/ARXIV.1905.11946</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-ebby_traditional_2024">
    <element-citation>
      <person-group person-group-type="author">
        <string-name>Ebby</string-name>
      </person-group>
      <article-title>The Traditional Attires Of Nigerian Tribes</article-title>
      <source>Inspiration with Lois Lifestyle  Nigeria</source>
      <year iso-8601-date="2024-06">2024</year><month>06</month>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-05-31">2025</year><month>05</month><day>31</day></date-in-citation>
      <uri>https://loispiration.com/2024/06/17/the-traditional-attires-of-nigerian-tribes/</uri>
    </element-citation>
  </ref>
  <ref id="ref-noauthor_culture_nodate">
    <element-citation>
      <article-title>Culture – MFA Press Center</article-title>
      <date-in-citation content-type="access-date"><year iso-8601-date="2025-05-31">2025</year><month>05</month><day>31</day></date-in-citation>
      <uri>https://foreignaffairs.gov.ng/nigeria/nigeria-culture/</uri>
    </element-citation>
  </ref>
</ref-list>
</back>



</article>