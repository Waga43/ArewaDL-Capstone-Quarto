<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
    <meta charset="utf-8">
    <meta name="generator" content="quarto-1.6.42">

    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

    <meta name="author" content="Karim Botros">
    <meta name="author" content="Mohammad Alkhatib">
    <meta name="author" content="David Folio">
    <meta name="author" content="Antoine Ferreira">
    <meta name="dcterms.date" content="2023-04-05">
    <meta name="keywords" content="Micro/nano robots, Medical robots and systems, deep learning methods.">
    <meta name="description" content="This is the capstone project for the Arewa Data Science Academy Deep Learning Cohort II (Group 9). The project focuses on using Deep Learning to classify images of Nigerian traditional attire into their respective ethnic categories.">

    <title>USMicroMagSet: Using Deep Learning Analysis to Benchmark the Performance of Microrobots in Ultrasound Images</title>
    <style>
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      div.columns{display: flex; gap: min(4vw, 1.5em);}
      div.column{flex: auto; overflow-x: auto;}
      div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
      ul.task-list{list-style: none;}
      ul.task-list li input[type="checkbox"] {
        width: 0.8em;
        margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
        vertical-align: middle;
      }
      /* CSS for citations */
      div.csl-bib-body { }
      div.csl-entry {
        clear: both;
        margin-bottom: 0em;
      }
      .hanging-indent div.csl-entry {
        margin-left:2em;
        text-indent:-2em;
      }
      div.csl-left-margin {
        min-width:2em;
        float:left;
      }
      div.csl-right-inline {
        margin-left:2em;
        padding-left:1em;
      }
      div.csl-indent {
        margin-left: 2em;
      }    </style>

    <style>
      body.hypothesis-enabled #quarto-embed-header {
        padding-right: 36px;
      }

      #quarto-embed-header {
        height: 3em;
        width: 100%;
        display: flex;
        justify-content: space-between;
        align-items: center;
        border-bottom: solid 1px;
      }

      #quarto-embed-header h6 {
        font-size: 1.1em;
        padding-top: 0.6em;
        margin-left: 1em;
        margin-right: 1em;
        font-weight: 400;
      }

      #quarto-embed-header a.quarto-back-link,
      #quarto-embed-header a.quarto-download-embed {
        font-size: 0.8em;
        margin-top: 1em;
        margin-bottom: 1em;
        margin-left: 1em;
        margin-right: 1em;
      }

      .quarto-back-container {
        padding-left: 0.5em;
        display: flex;
      }

      .headroom {
          will-change: transform;
          transition: transform 200ms linear;
      }

      .headroom--pinned {
          transform: translateY(0%);
      }

      .headroom--unpinned {
          transform: translateY(-100%);
      }      
    </style>

    <script>
    window.document.addEventListener("DOMContentLoaded", function () {

      var header = window.document.querySelector("#quarto-embed-header");
      const titleBannerEl = window.document.querySelector("body > #title-block-header");
      if (titleBannerEl) {
        titleBannerEl.style.paddingTop = header.clientHeight + "px";
      }
      const contentEl = window.document.getElementById('quarto-content');
      for (const child of contentEl.children) {
        child.style.paddingTop = header.clientHeight + "px";
        child.style.marginTop = "1em";
      }

      // Use the article root if the `back` call doesn't work. This isn't perfect
      // but should typically work
      window.quartoBackToArticle = () => {
        var currentUrl = window.location.href;
        window.history.back();
        setTimeout(() => {
            // if location was not changed in 100 ms, then there is no history back
            if(currentUrl === window.location.href){              
                // redirect to site root
                window.location.href = ".....html";
            }
        }, 100);
      }

      const headroom = new window.Headroom(header, {
        tolerance: 5,
        onPin: function () {
        },
        onUnpin: function () {
        },
      });
      headroom.init();
    });
    </script>

    
<script src="../../site_libs/manuscript-notebook/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-32162a2fca7cb0439643f2faaab1edf3.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
     <script async="" src="https://hypothes.is/embed.js"></script>
<script>
  window.document.addEventListener("DOMContentLoaded", function (_event) {
    document.body.classList.add('hypothesis-enabled');
  });
</script>   <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script> 
      </head>

  <body class="quarto-notebook">
    <div id="quarto-embed-header" class="headroom fixed-top bg-primary">
      
      <a onclick="window.quartoBackToArticle(); return false;" class="btn btn-primary quarto-back-link" href=""><i class="bi bi-caret-left"></i> Back to Article</a>
      <h6><i class="bi bi-journal-code"></i> USMicroMagSet: Using Deep Learning Analysis to Benchmark the Performance of Microrobots in Ultrasound Images</h6>

            <a href="../../quarto-ieee/examples/2023botrosRAL.qmd" class="btn btn-primary quarto-download-embed" download="2023botrosRAL.qmd">Download Source</a>
          </div>

     <header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">USMicroMagSet: Using Deep Learning Analysis to Benchmark the Performance of Microrobots in Ultrasound Images</h1>
          </div>

    
    <div class="quarto-title-meta-container">
      <div class="quarto-title-meta-column-start">
            <div class="quarto-title-meta-author">
          <div class="quarto-title-meta-heading">Authors</div>
          <div class="quarto-title-meta-heading">Affiliations</div>
          
                <div class="quarto-title-meta-contents">
            <p class="author">Karim Botros <a href="https://orcid.org/0000-0003-0245-1852" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
          </div>
                <div class="quarto-title-meta-contents">
                    <p class="affiliation">
                        <a href="https://www.univ-orleans.fr/fr/prisme">
                        INSA Centre Val de Loire, Univ. Orl√©ans, PRISME EA4229
                        </a>
                      </p>
                  </div>
                      <div class="quarto-title-meta-contents">
            <p class="author">Mohammad Alkhatib <a href="https://orcid.org/0000-0003-0971-3835" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
          </div>
                <div class="quarto-title-meta-contents">
                    <p class="affiliation">
                        <a href="http://www.institutpascal.uca.fr">
                        Clermont Auvergne INP, CNRS, SIGMA Clermont
                        </a>
                      </p>
                  </div>
                      <div class="quarto-title-meta-contents">
            <p class="author"><a href="https://dfolio.fr/">David Folio</a> <a href="mailto:david.folio@insa-cvl.fr" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> <a href="https://orcid.org/0000-0001-9430-6091" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
          </div>
                <div class="quarto-title-meta-contents">
                    <p class="affiliation">
                        <a href="https://www.univ-orleans.fr/fr/prisme">
                        INSA Centre Val de Loire, Univ. Orl√©ans, PRISME EA4229
                        </a>
                      </p>
                  </div>
                      <div class="quarto-title-meta-contents">
            <p class="author">Antoine Ferreira <a href="mailto:antoine.ferreira@insa-cvl.fr" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> <a href="https://orcid.org/0000-0001-6295-3876" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
          </div>
                <div class="quarto-title-meta-contents">
                    <p class="affiliation">
                        <a href="https://www.univ-orleans.fr/fr/prisme">
                        INSA Centre Val de Loire, Univ. Orl√©ans, PRISME EA4229
                        </a>
                      </p>
                  </div>
                    </div>
        
        <div class="quarto-title-meta">

                      
                <div>
            <div class="quarto-title-meta-heading">Published</div>
            <div class="quarto-title-meta-contents">
              <p class="date">April 5, 2023</p>
            </div>
          </div>
          
                
              </div>
      </div>
      <div class="quarto-title-meta-column-end quarto-other-formats-target">
      </div>
    </div>

    <div>
      <div class="abstract">
        <div class="block-title">Abstract</div>
        <p>Microscale robots introduce great perspectives into many medical applications such as drug delivery, minimally invasive surgery, and localized biometric diagnostics. Fully automatic microrobots‚Äô real-time detection and tracking using medical imagers are actually investigated for future clinical translation. Ultrasound (US) B-mode imaging has been employed to monitor single agents and collective swarms of microrobots <em>in vitro</em> and <em>ex vivo</em> in controlled experimental conditions. However, low contrast and spatial resolution still limit the effective employment of such a method in a medical microrobotic scenario due to uncertainties associated with the position of microrobots. The positioning error arises due to the inaccuracy of the US-based visual feedback, which is provided by the detection and tracking algorithms. The application of deep learning networks is a promising solution to detect and track real-time microrobots in noisy ultrasonic images. However, what is most striking is the performance gap among state-of-the-art microrobots deep learning detection and tracking research. A key factor of that is the unavailability of large-scale datasets and benchmarks. In this paper, we present the first publicly available B-mode ultrasound dataset for microrobots (<em>USmicroMagSet</em>) with accurate annotations which contains more than 40000 samples of magnetic microrobots. In addition, for analyzing the performance of microrobots included in the proposed benchmark dataset, 4 deep learning detectors and 4 deep learning trackers are used.</p>
      </div>
    </div>

    <div>
      <div class="keywords">
        <div class="block-title">Keywords</div>
        <p>Micro/nano robots, Medical robots and systems, deep learning methods.</p>
      </div>
    </div>

    <div class="quarto-other-links-text-target">
    </div>  </div>
</header><div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-intro" id="toc-sec-intro" class="nav-link active" data-scroll-target="#sec-intro">Introduction</a></li>
  <li><a href="#sec-benchmarking" id="toc-sec-benchmarking" class="nav-link" data-scroll-target="#sec-benchmarking">Microrobot Benchmarking</a>
  <ul class="collapse">
  <li><a href="#classes" id="toc-classes" class="nav-link" data-scroll-target="#classes">Classes</a></li>
  <li><a href="#microrobot-principle" id="toc-microrobot-principle" class="nav-link" data-scroll-target="#microrobot-principle">Microrobot principle</a>
  <ul class="collapse">
  <li><a href="#steering-magnetic-field-smf-class" id="toc-steering-magnetic-field-smf-class" class="nav-link" data-scroll-target="#steering-magnetic-field-smf-class">Steering magnetic field (SMF) class</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
</div>
<main class="content quarto-banner-title-block" id="quarto-document-content">      

       <section id="sec-intro" class="level1">
<h1>Introduction</h1>
<div id="fig-dataset" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-pos="ht" data-fig-env="figure*">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-dataset-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="Figures/Figure1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Illustration of the three classes of eight swimming magnetic microrobots used for the USMicroMagset dataset. For each microrobot, 5k images were extracted from 5 videos of 10min each. (Row 1) Class SMF: Steering magnetic field with three subclasses (sphere, cube and cylinder) of hard NdFeB magnets. (Row 2) Class RMF: Rotating magnetic field with three subclasses (helix microrobot, soft magnetic sheet microrobot, cube microrobot). (Row 3) Class OMF: Oscillating magnetic field with two subclasses (chain-like swimmer, one-armed flagella swimmer with magnetic head)."><img src="Figures/Figure1.png" class="img-fluid figure-img" style="width:80.0%"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-dataset-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Illustration of the three classes of eight swimming magnetic microrobots used for the <span class="math inline">\(USMicroMagset\)</span> dataset. For each microrobot, 5k images were extracted from 5 videos of 10min each. (Row 1) Class SMF: Steering magnetic field with three subclasses (sphere, cube and cylinder) of hard NdFeB magnets. (Row 2) Class RMF: Rotating magnetic field with three subclasses (helix microrobot, soft magnetic sheet microrobot, cube microrobot). (Row 3) Class OMF: Oscillating magnetic field with two subclasses (chain-like swimmer, one-armed flagella swimmer with magnetic head).
</figcaption>
</figure>
</div>
<p><span class="IEEEPARstart">R</span><span>ecently</span> untethered mobile magnetic microrobots have been proposed for a wide range of biomedical applications (drug delivery, clot removal, tissue regeneration) <span class="citation" data-cites="li2017micro">Li (<a href="#ref-li2017micro" role="doc-biblioref">2017</a>)</span> due to their small size and ability to operate in confined spaces and hard-to-reach environments <span class="citation" data-cites="chung2021magnetically">Chung, Parsons, and Zheng (<a href="#ref-chung2021magnetically" role="doc-biblioref">2021</a>)</span>. In endovascular navigation, real-time localization and tracking of microrobots are essential for achieving targeted navigation through imaging feedback. To do so, various medical imaging technologies are being used for the detection and tracking of microrobots such as ultrasound (US) imaging, magnetic resonance imaging, computer tomography, infrared fluorescence imaging, X-ray, and positron emission tomography <span class="citation" data-cites="pane2019imaging">Pan√© et al. (<a href="#ref-pane2019imaging" role="doc-biblioref">2019</a>)</span>. Recently, there has been increasing attention towards the navigation of magnetic microrobots using active mode US imaging endorsed by healthcare applications <span class="citation" data-cites="scheggi2017magnetic">Scheggi et al. (<a href="#ref-scheggi2017magnetic" role="doc-biblioref">2017</a>)</span>. It can be explained by the fact that ultrasonic imaging is a noninvasive, versatile, low cost and well-established technique that is regularly used in medical settings. The ultrasound B-mode imaging was successfully used at different scales to detect and to track in real-time different robots <em>in vitro</em> and <em>in vivo</em>. For example at the millimeter-scale, soft grippers <span class="citation" data-cites="khalil2018mechanical">Khalil et al. (<a href="#ref-khalil2018mechanical" role="doc-biblioref">2018</a>)</span>, helical swimmers <span class="citation" data-cites="hu2018smallscale">Hu et al. (<a href="#ref-hu2018smallscale" role="doc-biblioref">2018</a>)</span> or soft-bodied robots <span class="citation" data-cites="ackermann2016detection">Ackermann and Schmitz (<a href="#ref-ackermann2016detection" role="doc-biblioref">2016</a>)</span> have been investigated. Different tracking techniques have been implemented to track the small-scale robots such as modified Markov chain Monte Carlo data association algorithm <span class="citation" data-cites="zhang2021kalman">Zhang et al. (<a href="#ref-zhang2021kalman" role="doc-biblioref">2021</a>)</span>, Kalman filtering <span class="citation" data-cites="zhang2021kalman">Zhang et al. (<a href="#ref-zhang2021kalman" role="doc-biblioref">2021</a>)</span>, and conventional neural networks <span class="citation" data-cites="tiryaki2022deep">Tiryaki, Demir, and Sitti (<a href="#ref-tiryaki2022deep" role="doc-biblioref">2022</a>)</span>. At the microscale, various types of microrobots were successfully demonstrated such as paramagnetic particles <span class="citation" data-cites="khalil2014magneticbase">Khalil et al. (<a href="#ref-khalil2014magneticbase" role="doc-biblioref">2014</a>)</span>, acoustically actuated microswimmer <span class="citation" data-cites="chen2019ultrasound">Chen et al. (<a href="#ref-chen2019ultrasound" role="doc-biblioref">2019</a>)</span>, self-propelled microjets <span class="citation" data-cites="sanchez2014magnetic">S√°nchez et al. (<a href="#ref-sanchez2014magnetic" role="doc-biblioref">2014</a>)</span> and bio-inspired magnetosperm <span class="citation" data-cites="magdanz2020ironsperm">Magdanz et al. (<a href="#ref-magdanz2020ironsperm" role="doc-biblioref">2020</a>)</span> in living tissue. However, the lack of B-mode resolution owing to poor microrobot echogenicity in image contrast, as well as the low signal-to-noise ratio (SNR), hinders the real-time tracking of microrobots in endovascular applications. To enhance spatial resolution, ultrasound phase analysis was implemented in <span class="citation" data-cites="pane2021realtime">Pane et al. (<a href="#ref-pane2021realtime" role="doc-biblioref">2021</a>)</span> to derive microrobot features such as size and position over time allowing to perform imaging and tracking of a low contrast microrobot in chicken breast. Finally, Doppler-based ultrasound appears as a promising tool for tracking microrobots in echogenic and dynamic environments as biological tissues. In <span class="citation" data-cites="wang2020realtime wang2021ultrasound">(<a href="#ref-wang2020realtime" role="doc-biblioref">Wang et al. 2020</a>, <a href="#ref-wang2021ultrasound" role="doc-biblioref">2021</a>)</span> a strategy to navigate a nanoparticle microswarm in real-time under ultrasound Doppler imaging guidance for active endovascular delivery was implemented in blood vessels. The Doppler signals near the microswarm in flowing blood environments were observed, and the microswarm was efficiently tracked and navigated in real-time using Doppler feedback. However, taking into the wide diversity of robot geometries and sizes, variability of swimming principles, and robot material echogenicity properties, the proposed state-of-the-art real-time detection and tracking methodologies face shadowing, low contrast, strong attenuation across an image, and fuzziness of vessel boundaries. Microrobot detection and tracking in vessels is a challenging task, particularly when using US imaging. These challenges in US images include speckle noise, dynamic backgrounds, blur, and US image artifacts. This drives the employment of deep learning-based methods to enhance microrobot detection and tracking in vessels <span class="citation" data-cites="liu2022capsule">Liu et al. (<a href="#ref-liu2022capsule" role="doc-biblioref">2022</a>)</span>. However, further research on deep learning detection of microrobots in US images is still not fully explored. Furthermore, convolution neural networks (CNN) models and frameworks may also be retrained using a customized dataset, offering deep learning techniques more flexibility than computer vision methods.</p>
<p>Moreover, deep learning-driven techniques yield promising performance for automatic detection and tracking of navigable magnetic microrobots using ultrasonic imaging <span class="citation" data-cites="botross2022fully">Botross et al. (<a href="#ref-botross2022fully" role="doc-biblioref">2022</a>)</span>. But, there is no well-established benchmarking dataset. Typically, some research teams test and report the performance of their technique on their own private dataset utilizing experimental setups designed expressly for that purpose. Consequently, comparing the performance of multiple approaches or predicting how a given methodology will perform if the experimental setup/conditions change is challenging.</p>
<p>In this work, we propose a public large-scale benchmarking dataset (<span class="math inline">\(USMicroMagset\)</span>), summarized in <span class="citation" data-cites="fig-dataset">(<a href="#ref-fig-dataset" role="doc-biblioref"><strong>fig-dataset?</strong></a>)</span>. The dataset consists of ultrasound B-mode images of magnetic microrobots with different aspect ratios, sizes (1 mm to 300 ¬µm), shapes, soft/rigid structures, and locomotion principles. This survey provides some insights into the challenges of detectability and trackability of a wide variety of magnetic microrobots navigating in microfluidic channels mimicking a vessel network. In addition, this dataset is used to perform a comprehensive survey of deep learning-based microrobot detection and tracking in ultrasonic B-mode images. Based on these comparative analyses <span class="citation" data-cites="srivastava2021comparative marvasti-zadeh2022deep">(<a href="#ref-srivastava2021comparative" role="doc-biblioref">Srivastava et al. 2021</a>; <a href="#ref-marvasti-zadeh2022deep" role="doc-biblioref">Marvasti-Zadeh et al. 2022</a>)</span>, we have extracted the best four detectors and the best four trackers. Then we evaluated these detectors and trackers on our dataset <span class="math inline">\(USMicroMagset\)</span>. Finally, using the best detector and tracker algorithms, we evaluated each microrobot under real-time challenging scenarios simulating in vivo imaging problems such as changing ultrasound parameters, changing speed of microrobot motion, partial and full occlusion, and out-of-plane motion.</p>
<p>The paper is organized as follows: <span class="citation" data-cites="sec-benchmarking">(<a href="#ref-sec-benchmarking" role="doc-biblioref"><strong>sec-benchmarking?</strong></a>)</span> describes the datasets and the methods used in the proposed work. Section 3 describes the deep learning detectors and trackers. Section 4 made a comparative assessment of the different detectors and trackers before concluding.</p>
</section>
<section id="sec-benchmarking" class="level1">
<h1>Microrobot Benchmarking</h1>
<section id="classes" class="level2">
<h2 class="anchored" data-anchor-id="classes">Classes</h2>
<p>In the proposed <span class="math inline">\(USMicroMagset\)</span> dataset, there are three different classes describing three operating principles of hard and soft magnetic microrobots. Our dataset is composed of 40k images subdivided into three classes of magnetic microrobots. <span class="citation" data-cites="fig-dataset">(<a href="#ref-fig-dataset" role="doc-biblioref"><strong>fig-dataset?</strong></a>)</span> summarizes the locomotion principles for each class of magnetic microrobot used in the datasets. We recorded 5k images for each microrobot prototype (80% for training and 20% for testing). All images have been annotated manually by an experienced expert.</p>
</section>
<section id="microrobot-principle" class="level2">
<h2 class="anchored" data-anchor-id="microrobot-principle">Microrobot principle</h2>
<p>Basically, governing equations of magnetized hard and soft microrobots controlled by magnetic fields are as follows : <span class="math display">\[\begin{eqnarray}
{\vb{\textbf{F}}_{m}}&amp;= \left(\vb{M}\cdot \nabla\right) \vb{B} \label{eq:Fm} \\
\vb{\textbf{T}_{m}}&amp;= \left(\vb{M}\times\vb{B}\right) \label{eq:Tm}
\end{eqnarray}\]</span> where <span class="math inline">\(\vb{\textbf{T}_{m}}\)</span> is the resultant magnetic torque; <span class="math inline">\(\vb{\textbf{F}_{m}}\)</span> is the resultant magnetic force; <span class="math inline">\(\vb{M}\)</span> is the magnetic moment of the object; <span class="math inline">\(\vb{B}\)</span> is the applied magnetic field. Depending on the actuating magnetic fields, three classes have been identified and tested:</p>
<section id="steering-magnetic-field-smf-class" class="level3">
<h3 class="anchored" data-anchor-id="steering-magnetic-field-smf-class">Steering magnetic field (SMF) class</h3>
<p>The first class consists of three subclasses of force-driven microrobots (Row;1 in <span class="citation" data-cites="fig-dataset">(<a href="#ref-fig-dataset" role="doc-biblioref"><strong>fig-dataset?</strong></a>)</span>) using various shapes of hard NdFeB magnets (spheres, cubes, and cylinders). The steering motion relies on the use of SMF induced by three-axis Maxwell pair coils.</p>
<p>The resultant steering force <span class="math inline">\(\vb{\textbf{F}_{m}}\)</span> provides a linear steering motion of the microrobot <span class="citation" data-cites="kummer2010octomag mathieu2010steeringa ghanbari2014electromagnetic">(<a href="#ref-kummer2010octomag" role="doc-biblioref">Kummer et al. 2010</a>; <a href="#ref-mathieu2010steeringa" role="doc-biblioref">Mathieu and Martel 2010</a>; <a href="#ref-ghanbari2014electromagnetic" role="doc-biblioref">Ghanbari et al. 2014</a>)</span></p>
<div class="center">
<p><strong>Full text are available from <a href="https://ieeexplore.ieee.org/document/10093014/">IEEEXplore<sup>¬Æ</sup></a></strong></p>
</div>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-ackermann2016detection" class="csl-entry" role="listitem">
Ackermann, Dimitri, and Georg Schmitz. 2016. <span>‚ÄúDetection and <span>Tracking</span> of <span>Multiple Microbubbles</span> in <span>Ultrasound B-Mode Images</span>.‚Äù</span> <em>IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control</em> 63 (1): 72‚Äì82. <a href="https://doi.org/10.1109/TUFFC.2015.2500266">https://doi.org/10.1109/TUFFC.2015.2500266</a>.
</div>
<div id="ref-botross2022fully" class="csl-entry" role="listitem">
Botross, Karim, Mohammad Alkhatib, David Folio, and Antoine FERREIRA. 2022. <span>‚ÄúFully <span>Automatic</span> and <span>Real-Time Microrobot Detection</span> and <span>Tracking</span> Based on <span>Ultrasound Imaging</span> Using <span>Deep Learning</span>.‚Äù</span> In <em>Proc. IEEE Int. Conf. Robot. Automat.</em> <span>Philadelphia, US</span>: <span>IEEE</span>. <a href="https://doi.org/10.1109/ICRA46639.2022.9812114">https://doi.org/10.1109/ICRA46639.2022.9812114</a>.
</div>
<div id="ref-chen2019ultrasound" class="csl-entry" role="listitem">
Chen, Qiyang, Fang-Wei Liu, Zunding Xiao, Nitin Sharma, Sung Kwon Cho, and Kang Kim. 2019. <span>‚ÄúUltrasound Tracking of the Acoustically Actuated Microswimmer.‚Äù</span> <em><span>IEEE</span> Trans. Biomed. Eng.</em> 66 (11): 3231‚Äì37. <a href="https://doi.org/10.1109/TBME.2019.2902523">https://doi.org/10.1109/TBME.2019.2902523</a>.
</div>
<div id="ref-chung2021magnetically" class="csl-entry" role="listitem">
Chung, Hyun-Joong, Andrew M. Parsons, and Lelin Zheng. 2021. <span>‚ÄúMagnetically <span>Controlled Soft Robotics Utilizing Elastomers</span> and <span>Gels</span> in <span>Actuation</span>: <span>A Review</span>.‚Äù</span> <em>Adv. Int.Syst</em> 3 (3): 2000186. <a href="https://doi.org/10.1002/aisy.202000186">https://doi.org/10.1002/aisy.202000186</a>.
</div>
<div id="ref-ghanbari2014electromagnetic" class="csl-entry" role="listitem">
Ghanbari, Ali, Pyung H. Chang, Bradley J. Nelson, and Hongsoo Choi. 2014. <span>‚ÄúElectromagnetic <span>Steering</span> of a <span>Magnetic Cylindrical Microrobot Using Optical Feedback Closed-Loop Control</span>.‚Äù</span> <em>Int. J. Optomechatron.</em> 8 (2): 129‚Äì45. <a href="https://doi.org/10.1080/15599612.2014.901454">https://doi.org/10.1080/15599612.2014.901454</a>.
</div>
<div id="ref-hu2018smallscale" class="csl-entry" role="listitem">
Hu, Wenqi, Guo Zhan Lum, Massimo Mastrangeli, and Metin Sitti. 2018. <span>‚ÄúSmall-Scale Soft-Bodied Robot with Multimodal Locomotion.‚Äù</span> <em>Nature</em> 554 (7690, 7690): 81‚Äì85. <a href="https://doi.org/10.1038/nature25443">https://doi.org/10.1038/nature25443</a>.
</div>
<div id="ref-khalil2014magneticbase" class="csl-entry" role="listitem">
Khalil, Islam S. M., Pedro Ferreira, Ricardo Eleut√©rio, Chris L. de Korte, and Sarthak Misra. 2014. <span>‚ÄúMagnetic-Based Closed-Loop Control of Paramagnetic Microparticles Using Ultrasound Feedback.‚Äù</span> In <em>Proc. IEEE Int. Conf. Robot. Automat.</em>, 3807‚Äì12. <a href="https://doi.org/10.1109/ICRA.2014.6907411">https://doi.org/10.1109/ICRA.2014.6907411</a>.
</div>
<div id="ref-khalil2018mechanical" class="csl-entry" role="listitem">
Khalil, Islam S. M., Dalia Mahdy, Ahmed El Sharkawy, Ramez R. Moustafa, Ahmet Fatih Tabak, Mohamed E. Mitwally, Sarah Hesham, et al. 2018. <span>‚ÄúMechanical <span>Rubbing</span> of <span>Blood Clots Using Helical Robots Under Ultrasound Guidance</span>.‚Äù</span> <em><span>IEEE</span> Robot. Autom. Lett.</em> 3 (2): 1112‚Äì19. <a href="https://doi.org/10.1109/LRA.2018.2792156">https://doi.org/10.1109/LRA.2018.2792156</a>.
</div>
<div id="ref-kummer2010octomag" class="csl-entry" role="listitem">
Kummer, Michael Philipp, Jake J. Abbott, Bradley E. Kratochvil, Ruedi Borer, Ali Sengul, and Bradley J. Nelson. 2010. <span>‚ÄúOctomag: <span>An</span> Electromagnetic System for 5-<span>DOF</span> Wireless Micromanipulation.‚Äù</span> <em><span>IEEE</span> Trans. Robot.</em> 26 (6): 1006‚Äì17. <a href="https://doi.org/10.1109/TRO.2010.2073030">https://doi.org/10.1109/TRO.2010.2073030</a>.
</div>
<div id="ref-li2017micro" class="csl-entry" role="listitem">
Li, Jinxing et al. 2017. <span>‚ÄúMicro/Nanorobots for Biomedicine: <span>Delivery</span>, Surgery, Sensing, and Detoxification.‚Äù</span> <em>Sci. Robot.</em> 2 (4).
</div>
<div id="ref-liu2022capsule" class="csl-entry" role="listitem">
Liu, Xiaoyun, Daniel Esser, Brandon Wagstaff, Anna Zavodni, Naomi Matsuura, Jonathan Kelly, and Eric Diller. 2022. <span>‚ÄúCapsule Robot Pose and Mechanism State Detection in Ultrasound Using Attention-Based Hierarchical Deep Learning.‚Äù</span> <em>Scientific Reports</em> 12 (1, 1): 21130. <a href="https://doi.org/10.1038/s41598-022-25572-w">https://doi.org/10.1038/s41598-022-25572-w</a>.
</div>
<div id="ref-magdanz2020ironsperm" class="csl-entry" role="listitem">
Magdanz, Veronika, Islam S. M. Khalil, Juliane Simmchen, Guilherme P. Furtado, Sumit Mohanty, Johannes Gebauer, Haifeng Xu, et al. 2020. <span>‚Äú<span>IRONSperm</span>: <span class="nocase">Sperm-templated</span> Soft Magnetic Microrobots.‚Äù</span> <em>Science Advances</em> 6 (28). <a href="https://doi.org/10.1126/sciadv.aba5855">https://doi.org/10.1126/sciadv.aba5855</a>.
</div>
<div id="ref-marvasti-zadeh2022deep" class="csl-entry" role="listitem">
Marvasti-Zadeh, Seyed Mojtaba, Li Cheng, Hossein Ghanei-Yakhdan, and Shohreh Kasaei. 2022. <span>‚ÄúDeep <span>Learning</span> for <span>Visual Tracking</span>: <span>A Comprehensive Survey</span>.‚Äù</span> <em><span>IEEE</span> Trans. Intell. Transp. Syst.</em> 23 (5): 3943‚Äì68. <a href="https://doi.org/10.1109/TITS.2020.3046478">https://doi.org/10.1109/TITS.2020.3046478</a>.
</div>
<div id="ref-mathieu2010steeringa" class="csl-entry" role="listitem">
Mathieu, Jean-Baptiste, and Sylvain Martel. 2010. <span>‚ÄúSteering of Aggregating Magnetic Microparticles Using Propulsion Gradients Coils in an <span>MRI Scanner</span>.‚Äù</span> <em>Magnetic Resonance in Medicine</em> 63 (5): 1336‚Äì45. <a href="https://doi.org/10.1002/mrm.22279">https://doi.org/10.1002/mrm.22279</a>.
</div>
<div id="ref-pane2021realtime" class="csl-entry" role="listitem">
Pane, S., V. Iacovacci, E. Sinibaldi, and A. Menciassi. 2021. <span>‚ÄúReal-Time Imaging and Tracking of Microrobots in Tissues Using Ultrasound Phase Analysis.‚Äù</span> <em>Applied Physics Letters</em> 118 (1): 014102. <a href="https://doi.org/10.1063/5.0032969">https://doi.org/10.1063/5.0032969</a>.
</div>
<div id="ref-pane2019imaging" class="csl-entry" role="listitem">
Pan√©, Salvador, Josep Puigmart√≠-Luis, Christos Bergeles, Xiang-Zhong Chen, Eva Pellicer, Jordi Sort, Vanda Poƒçepcov√°, Antoine Ferreira, and Bradley J. Nelson. 2019. <span>‚ÄúImaging <span>Technologies</span> for <span>Biomedical Micro-</span> and <span>Nanoswimmers</span>.‚Äù</span> <em>Adv. Mater. Technol.</em> 4 (4): 1800575. <a href="https://doi.org/10.1002/admt.201800575">https://doi.org/10.1002/admt.201800575</a>.
</div>
<div id="ref-sanchez2014magnetic" class="csl-entry" role="listitem">
S√°nchez, Alonso, Veronika Magdanz, Oliver G. Schmidt, and Sarthak Misra. 2014. <span>‚ÄúMagnetic Control of Self-Propelled Microjets Under Ultrasound Image Guidance.‚Äù</span> <em>IEEE RAS/EMBS International Conference on Biomedical Robotics and Biomechatronics</em>, 169‚Äì74. <a href="https://doi.org/10.1109/BIOROB.2014.6913771">https://doi.org/10.1109/BIOROB.2014.6913771</a>.
</div>
<div id="ref-scheggi2017magnetic" class="csl-entry" role="listitem">
Scheggi, Stefano, Krishna Kumar T. Chandrasekar, ChangKyu Yoon, Ben Sawaryn, Gert van de Steeg, David H. Gracias, and Sarthak Misra. 2017. <span>‚ÄúMagnetic Motion Control and Planning of Untethered Soft Grippers Using Ultrasound Image Feedback.‚Äù</span> In <em>Proc. IEEE Int. Conf. Robot. Automat.</em>, 6156‚Äì61. <a href="https://doi.org/10.1109/ICRA.2017.7989730">https://doi.org/10.1109/ICRA.2017.7989730</a>.
</div>
<div id="ref-srivastava2021comparative" class="csl-entry" role="listitem">
Srivastava, Shrey, Amit Vishvas Divekar, Chandu Anilkumar, Ishika Naik, Ved Kulkarni, and V. Pattabiraman. 2021. <span>‚ÄúComparative Analysis of Deep Learning Image Detection Algorithms.‚Äù</span> <em>Journal of Big Data</em> 8 (1): 66. <a href="https://doi.org/10.1186/s40537-021-00434-w">https://doi.org/10.1186/s40537-021-00434-w</a>.
</div>
<div id="ref-tiryaki2022deep" class="csl-entry" role="listitem">
Tiryaki, Mehmet Efe, Sinan Ozgun Demir, and Metin Sitti. 2022. <span>‚ÄúDeep <span class="nocase">Learning-based 3D Magnetic Microrobot Tracking</span> Using <span>2D MR Images</span>.‚Äù</span> <em><span>IEEE</span> Robot. Autom. Lett.</em> 7 (3): 6982‚Äì89. <a href="https://doi.org/10.1109/LRA.2022.3179509">https://doi.org/10.1109/LRA.2022.3179509</a>.
</div>
<div id="ref-wang2021ultrasound" class="csl-entry" role="listitem">
Wang, Qianqian, Kai Fung Chan, Kathrin Schweizer, Xingzhou Du, Dongdong Jin, Simon Chun Ho Yu, Bradley J. Nelson, and Li Zhang. 2021. <span>‚ÄúUltrasound <span class="nocase">Doppler-guided</span> Real-Time Navigation of a Magnetic Microswarm for Active Endovascular Delivery.‚Äù</span> <em>Science Advances</em> 7 (9): eabe5914. <a href="https://doi.org/10.1126/sciadv.abe5914">https://doi.org/10.1126/sciadv.abe5914</a>.
</div>
<div id="ref-wang2020realtime" class="csl-entry" role="listitem">
Wang, Qianqian, Lidong Yang, Jiangfan Yu, Philip Wai Yan Chiu, Yong-Ping Zheng, and Li Zhang. 2020. <span>‚ÄúReal-<span>Time Magnetic Navigation</span> of a <span>Rotating Colloidal Microswarm Under Ultrasound Guidance</span>.‚Äù</span> <em><span>IEEE</span> Trans. Biomed. Eng.</em> 67 (12): 3403‚Äì12. <a href="https://doi.org/10.1109/TBME.2020.2987045">https://doi.org/10.1109/TBME.2020.2987045</a>.
</div>
<div id="ref-zhang2021kalman" class="csl-entry" role="listitem">
Zhang, Heng, Hongwu Zhan, Libin Zhang, Fang Xu, and Xinbin Ding. 2021. <span>‚ÄúA <span>Kalman Filter-Based Kernelized Correlation Filter Algorithm</span> for <span>Pose Measurement</span> of a <span>Micro-Robot</span>.‚Äù</span> <em>Micromachines</em> 12 (7, 7): 774. <a href="https://doi.org/10.3390/mi12070774">https://doi.org/10.3390/mi12070774</a>.
</div>
</div>
</section>
</section>
</section>
     </main>
<!-- /main column -->  <script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>  </div> <!-- /content -->  <script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script> 
  
</body></html>